{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to manipulate some of the regression algorithms of [scikit-learn](http://scikit-learn.org/stable/documentation.html). We will also use the [pandas library](https://pandas.pydata.org/) to manipulate data.\n",
    "\n",
    "This notebook was created by [Chloé-Agathe Azencott](http://cazencott.info)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created using\n",
    "* python 3.4.3\n",
    "* numpy 1.15.0\n",
    "* matplotlib 2.2.2\n",
    "* scikit-learn 0.19.2\n",
    "\n",
    "You can check your version of Python by running\n",
    "```python\n",
    "import sys\n",
    "print(sys.version)\n",
    "```\n",
    "\n",
    "and the version of any module by running\n",
    "```python\n",
    "import <module name>\n",
    "print(<module name>.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data science libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting prostate-specific antigen levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prostate-specific antigen, or PSA, is a protein produced by cells of the prostate gland. \n",
    "\n",
    "The concentration of PSA in a man's blood is often elevated in men with prostate cancer, and it is used to monitor the progression of prostate cancer. \n",
    "\n",
    "The goal of this lab is to predict the concentration of PSA (`lpsa`, given in log scale) from other clinical measurements, which are:\n",
    "* `cavol`: the tumor volume (given in log scale)\n",
    "* `lweight`: the weight of the prostate (given in log scale)\n",
    "* `age`: the patient's age\n",
    "* `lbph`: the volume of benign prostatic hyperplasia, that is to say, non-cancerous enlargement of the prostate (given in log scale)\n",
    "* `svi`: whether the seminal vesical has been invaved by the cancer\n",
    "* `lcp`: the capsular penetration, i.e. how much of the prostate capsule (= the membrane that surrounds the cancer gland) has been invaded by the cancer (given in log scale)\n",
    "* `gleason`: the Gleason score given by the physician. The Gleason score is given by a histopathologist after having looked at a biopsy of the prostate. You can read more about the Gleason score here: http://www.wikiwand.com/en/Gleason_grading_system. \n",
    "* `pgg45`: the percentage of the tumor that is given a Gleason score of 4 or 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are available as `data/Prostate.csv`. Let us load them in a pandas DataFrame called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Prostate.csv', \n",
    "                 index_col=0 # the first column is the IDs of the samples\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the first few lines of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.1 Split the data into a train set and a test set\n",
    "\n",
    "We will use the first 65 samples of the data for training our models, and the remaining samples to evaluate them. \n",
    "\n",
    "The last column, 'lpsa', is our target variable. \n",
    "\n",
    "Let us create the numpy arrays `Xtrain`, `Xtest` and the vectors `ytrain`, `ytest` that we will work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xtrain = df.iloc[:65, # first 65 lines\n",
    "                 :-1] # exclude last column\n",
    "ytrain = df.iloc[:65, -1]\n",
    "\n",
    "Xtest = df.iloc[65:, :-1]\n",
    "ytest = df.iloc[65:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ How many test samples do we have? How many features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.2 Data standardization\n",
    "\n",
    "One of the first things you can observe is that the values of the different features cover different ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"%.2e\" % np.min(df['lcavol']), \"%.2e\" % np.max(df['lcavol']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question : __ What is the range of the age variable? of the Gleason score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer :__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some methods will give more importance to the features with large absolute values of scores than to others, we will start by standardizing the data, i.e. making sure that each feature has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "To do this, we need to substract to each feature its mean (across all available samples), and divide by its standard deviation (across all available samples).\n",
    "\n",
    "__IMPORTANT__: Remember, we are pretending that the test set is hidden to us at learning time. This means we need to standardize the data _based on the training data only_.\n",
    "\n",
    "We will use scikit-learn's [preprocessing.StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Create a standardizer object and fit it to the training data.\n",
    "std_scale = preprocessing.StandardScaler().fit(Xtrain)\n",
    "\n",
    "# Apply the standardization to the training and the test data.\n",
    "Xtrain_std = std_scale.transform(Xtrain)\n",
    "Xtest_std = std_scale.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.3 Model selection by cross-validation\n",
    "Remember, using the test data to select our best model is likely to result in _overfitting_. \n",
    "\n",
    "We will therefore start by splitting the training data into 5 folds of cross-validation. Scikit-learn also does that for us.\n",
    "\n",
    "scikit-learn model selection: http://scikit-learn.org/stable/model_selection.html#model-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Créate a KFold object\n",
    "kf = model_selection.KFold(n_splits=5,  # 5 folds\n",
    "                           shuffle=True # shuffle the samples before splitting \n",
    "                          )\n",
    "\n",
    "# Use kf to split Xtrain_std into 5 folds. \n",
    "# kf.split returns an iterator ((that would be consumed after one iteration). \n",
    "# We transform it in a list (on which we can iterate as often as we want).\n",
    "kf_indices = list(kf.split(Xtrain_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, (tr, te) in enumerate(kf_indices):\n",
    "    print(\"Training data for fold %d:\" % i, tr)\n",
    "    print(\"Test data for fold %d:\" % i, te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ Write code to compute the number of samples in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Linear models\n",
    "\n",
    "We will use scikit-learn to train a few [linear models](http://scikit-learn.org/stable/modules/linear_model.html#linear-model) on `(Xtrain_std, ytrain_std)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1 inear regression\n",
    "How does a linear regression perform on this data? We'll evaluate it by cross-validation, using the cross-validation folds we have generated above.\n",
    "\n",
    "But wait! What will our criterion be? There are several you can choose from on http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter. In this lab, we will use the Mean Squared Error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ What other criterion or criteria could you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Annswer:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn allows us to directly compute the cross-validated MSE (on the train test) of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse = model_selection.cross_val_score(model, \n",
    "                                      Xtrain_std, y=ytrain, \n",
    "                                      scoring='neg_mean_squared_error', \n",
    "                                      cv=kf_indices)\n",
    "\n",
    "print([\"%.3f\" % value for value in nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What we obtained here is the opposite ('neg') of the mean squared error, for each fold.\n",
    "\n",
    "__Question:__ Why do you think scikit-learn implemented the _opposite_ of the mean squared error, rather than the mean squared error itself, or the more commonly used root mean squared error (i.e. the squared root of the mean squared error, usually denoted RMSE)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ What is the average RMSE of the linear regression over all folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What are the weights that a linear regression assigns to each variable on the train set? To determine this, we will train a linear regression on the entire training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train a linear regression on the entire train set\n",
    "model.fit(Xtrain_std, ytrain)\n",
    "\n",
    "# Plot, for each feature, its coefficient in the model\n",
    "num_features = Xtrain_std.shape[1]\n",
    "plt.scatter(range(num_features), model.coef_)\n",
    "\n",
    "plt.xlabel('Feature', fontsize=14)\n",
    "tmp = plt.xticks(range(num_features), list(df.columns), rotation=30, fontsize=14)\n",
    "tmp = plt.ylabel('Weight', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Linear regression weights', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Which feature do you think is the most important to predict PSA levels? Which one is the least important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.2 Ridge regression\n",
    "\n",
    "Can we improve performance using regularization? Let us look at [ridge regression]( http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression):\n",
    "\n",
    "Remember, in ridge regression there is a hyperparameter, called $\\alpha$, that controls the amount of regularization we use. We will cross-validate a ridge regression on the training data for several values of $\\alpha$.\n",
    "\n",
    "Let us create 50 values of alpha for testing, equally spaced (in log scale) between $10^{-1}$ and $10^4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-1, 4, 50)\n",
    "\n",
    "nmse_per_alpha = [] # will store the -MSE values for all 50 values of alpha\n",
    "weights_per_alpha = [] #  will store the weights associated with each feature \n",
    "                       # for all 50 values of alpha\n",
    "for alf in alphas:\n",
    "    # Create a regression ridge model\n",
    "    model = linear_model.Ridge(alpha=alf)\n",
    "    \n",
    "    # Compute the model's cross-validated performance\n",
    "    nmse = model_selection.cross_val_score(model, \n",
    "                                           Xtrain_std, y=ytrain, \n",
    "                                           scoring='neg_mean_squared_error', \n",
    "                                           cv=kf_indices)\n",
    "    nmse_per_alpha.append(nmse)\n",
    "    \n",
    "    # Train the model on the entire data set and store the regression coefficients\n",
    "    model.fit(Xtrain_std, ytrain)\n",
    "    weights_per_alpha.append(model.coef_)\n",
    "    \n",
    "# Plot, for each feature, the regression weight as a function of alpha\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "lines = plt.plot(alphas, weights_per_alpha)\n",
    "plt.xscale('log')\n",
    "tmp = plt.legend(lines, list(df.columns), frameon=False, loc='upper right', fontsize=14)\n",
    "\n",
    "tmp = plt.xlabel('alpha', fontsize=14)\n",
    "tmp = plt.ylabel('Weight', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Ridge regression weights', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Is this consistent with what we observed for the linear regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Plot the RMSE (averaged across the 5 folds) as a function of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ What is the optimal value of $\\alpha$ and what is the corresponding average cross-validated RMSE? Use `np.argmin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ How does the regularized ridge regression compare to the linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Non-linear models\n",
    "\n",
    "Can non-linear models improve the performance on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1 Random forest\n",
    "\n",
    "We will create a random forest with 50 trees.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "# Compute the cross-validation performance of this model \n",
    "nmse = model_selection.cross_val_score(model, \n",
    "                                       Xtrain_std, y=ytrain, \n",
    "                                       scoring='neg_mean_squared_error', \n",
    "                                       cv=kf_indices)\n",
    "\n",
    "print(nmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ What is the average RMSE of the linear regression over all folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Random forests assign a feature importance score to each variable (depending on how useful they are when building the model). Let us visualize them as we did the regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(Xtrain_std, ytrain)\n",
    "\n",
    "num_features = Xtrain_std.shape[1]\n",
    "plt.scatter(range(num_features), model.feature_importances_)\n",
    "\n",
    "plt.xlabel('Feature', fontsize=14)\n",
    "tmp = plt.xticks(range(num_features), list(df.columns), rotation=30, fontsize=14)\n",
    "tmp = plt.ylabel('Importance score', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Random forest feature importance', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ How does this compare to the features that had high weights in the linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2 Optional questions:\n",
    "\n",
    "* Repeat the analysis for several values of the number of trees in the forest.\n",
    "* Use an SVM on the data? Which parameter(s) do you have to set? What is the best cross-validated RMSE you obtain? See: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 5. Final model\n",
    "\n",
    "__Question:__ Based on the above analyses, which model do you finally choose as the most performant? What is its RMSE on the test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
