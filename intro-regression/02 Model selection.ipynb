{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to start using scikit-learn for model selection. We will use a simple regression algorithm, the k-nearest-neighbor, on the `vinho verde` data set, and try to find the best value for k.\n",
    "\n",
    "You will also learn how to standardize features, and use the `pandas` library for simple data manipulation.\n",
    "\n",
    "This notebook was created by [Chloé-Agathe Azencott](http://cazencott.info).\n",
    "\n",
    "Throughout the lab, do not hesitate to refer heavily to the [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created using\n",
    "* python 3.4.3\n",
    "* numpy 1.15.0\n",
    "* matplotlib 2.2.2\n",
    "* scikit-learn 0.19.2\n",
    "* pandas 0.22.0\n",
    "\n",
    "You can check your version of Python by running\n",
    "```python\n",
    "import sys\n",
    "print(sys.version)\n",
    "```\n",
    "\n",
    "and the version of any module by running\n",
    "```python\n",
    "import <module name>\n",
    "print(<module name>.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading our data science libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vinho verde` data set contains physico-chemical information on a number of Portuguese wines, as well as their rating by human tasters. \n",
    "\n",
    "Our goal is to use these data to automatically predict the rating of a wine, so as to assist oenologists, improve wine production, and target the taste of niche consumers.\n",
    "\n",
    "This data set has been made available on the UCI archive repository (it is one of the oldest and most well-known repository of ML problems).\n",
    "\n",
    "It is available from: http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/ (but already in your repository; we will focus on white wines here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/winequality-white.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded the data in a _pandas DataFrame_ object. Let us examine what information is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 12 columns. The first 10 (fixed acidity -- alcohol) are physico-chemical features of the wines; the last one is their rating (or quality).\n",
    "\n",
    "Let us extract from this data a numpy array that contains the design matrix X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, :-1]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1:__ Extract from this data a one-dimensional numpy array that contains the labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "y = data.values[:, -1]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot a histogram of the values taken by each of our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure of size 16x12\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "for feat_idx in range(X.shape[1]):\n",
    "    # create a subplot in the (feat_idx+1) position of a 3x4 grid\n",
    "    ax = fig.add_subplot(3, 4, (feat_idx+1))\n",
    "    # plot the histogram of feat_idx\n",
    "    h = ax.hist(X[:, feat_idx], bins=50, color='steelblue',\n",
    "                edgecolor='none')\n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(data.columns[feat_idx], fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2:__\n",
    "What are the ranges of values taken by the different features? What do you think is going to happen when one computes the euclidean distance between two samples: will the `free sulfur dioxide` be accounted for in a manner similar to the `sulphates`? How is this going to affect the k-nearest-neighbor algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider this problem as a regression problem. Note that it is not necessarily the best way to address this problem! In particular, a regression prediction will not be restricted to integer scores on a limited scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by separating our data into a training and a test set (containing 30% of the data). We will use cross-validation _on the training set_ to select the value of k, and we will report the performance of the selected model on the test set, as an approximation to the _generalization performance_ of our model.\n",
    "\n",
    "This can be done with scikit-learn's [model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.3 # 30% des données dans le jeu de test\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have observed in Section 2, the features need to be _standardized_ so as to be more or less on the same scale. We will achieve this by forcing them to have 0 mean and standard deviation 1. They will therefore all have the same importance to the eyes of a distance-based learning algorithm.\n",
    "\n",
    "We will use scikit-learn's [preprocessing.StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Create a standardizer object and fit it to the training data.\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Apply the standardization to the training and the test data.\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3:__ Why did we fit the standardizer (i.e. computed the mean and standard deviation for each feature) on the training set only?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4:__ Visualize the scaled data again to check that the standardization had the intended effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model selection by cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now choose the optimal value of k (the number of neighbors) in a k-nearest neighbor algorithm using a cross-validation procedure _on the training set_.\n",
    "\n",
    "This can be done using scikit-learn's [model_selection.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "In addition, we will need scikit-learn's (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor)[neighbors.KNeighborsRegressor] to implement a regression with a k-nearest neighbors algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# Set the values of the hyperparameter to test\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Pick a score to optimize, here the correlation coefficient r2\n",
    "score = 'r2'\n",
    "\n",
    "# Build a kNN classifier with hyperparameter search by cross-validation:\n",
    "predictor = model_selection.GridSearchCV(neighbors.KNeighborsRegressor(), # a kNN\n",
    "                                   param_grid, # hyperparameters to test\n",
    "                                   cv=5, # number of folds of the cross-validation\n",
    "                                   scoring=score # score to optimize\n",
    "                                  )\n",
    "\n",
    "# Optimize the classifier on the standardized training data\n",
    "predictor.fit(X_train_std, y_train)\n",
    "\n",
    "# Print optimal hyperparameter(s)\n",
    "print(\"Best hyperparameter(s) on the training set:\",\n",
    "       predictor.best_params_)\n",
    "\n",
    "# Print performance\n",
    "print(\"Cross-validation results:\")\n",
    "for mean, std, params in zip(predictor.cv_results_['mean_test_score'], # mean score on test set\n",
    "                             predictor.cv_results_['std_test_score'], # standard deviation\n",
    "                             predictor.cv_results_['params'] # value of the hyperparameter\n",
    "                            ):\n",
    "    print(\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, # performance\n",
    "                                              mean, # mean score\n",
    "                                              std * 2, # error bar\n",
    "                                              params # hyperparameter\n",
    "                                              ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Generalization performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now report the performance of our best model (it is automatically stored in `predictor`) on the test set.\n",
    "\n",
    "We will use scikit-learn's [metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module to this end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = predictor.predict(X_test_std)\n",
    "print(\"R2 on the test set: %0.3f\" % metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5__ Compute the root mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
