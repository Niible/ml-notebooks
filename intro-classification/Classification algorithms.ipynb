{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to manipulate some of the classification algorithms of [scikit-learn](http://scikit-learn.org/stable/documentation.html). \n",
    "\n",
    "This notebook was created by [Chloé-Agathe Azencott](http://cazencott.info)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created using\n",
    "* python 3.4.3\n",
    "* numpy 1.15.0\n",
    "* matplotlib 2.2.2\n",
    "* scikit-learn 0.19.2\n",
    "\n",
    "You can check your version of Python by running\n",
    "```python\n",
    "import sys\n",
    "print(sys.version)\n",
    "```\n",
    "\n",
    "and the version of any module by running\n",
    "```python\n",
    "import <module name>\n",
    "print(<module name>.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data science libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting mushroom edibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a data set that describes mushrooms according to the shape of their cap and stalk, their odor, the type of their veil, etc. This data set also contains information on whether a mushroom is edible or not, and that is what we will try to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are available as `data/mushrooms.csv`. Let us load them in a pandas DataFrame called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mushrooms.csv', \n",
    "                 #index_col=0 # the first column is the IDs of the samples\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the first few lines of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Converting the features into numerical values\n",
    "\n",
    "As you can see, the features are encoded as _letters_. Each letter correspond to a category . For example, for the `cap shape` feature, `b` corresponds to a bell cap, `c` to a conical cap, `f` to a flat cap, `k` to a knobbed cap, `s` to a sunken cap, and `x` to a convex cap. For more details about their meaning, you can consult [the documentation of the data set](https://archive.ics.uci.edu/ml/datasets/Mushroom).\n",
    "\n",
    "In order to work with this data, we need to convert the categorical attributes into numerical values. Here we will simply convert each letter to a number between 0 and the number of categories, using scikit-learn's [preprocessing.LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "This encoding is not necessarily the best, as (for example), an algorithm that uses the Euclidean distance will consider that a convex cap (`x` converted to 5) is closer to a sunken cap (`s` converted to 4) than to a conical cap (`c` converted to 1), and the [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features) is a good alternative. However, it has the drawback of increasing the number of features, and of creating correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "for col in df.columns:\n",
    "    df[col] = labelencoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.2 Split the data into a train set and a test set\n",
    "\n",
    "Let us first extact the design matrix `X` and the label vector `y` from the data frame.\n",
    "\n",
    "The first column, `class`, is our target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:] # exclude first column\n",
    "y = df.iloc[:, 0]  # first column only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 70% of the samples of the data for training our models, and the remaining samples to evaluate them.\n",
    "\n",
    "Let us create the numpy arrays `Xtrain`, `Xtest` and the vectors `ytrain`, `ytest` that we will work with, using scikit-learn's [model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "Xtrain, Xtest, ytrain, ytest = model_selection.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ How many training and test samples do we have? How many features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.3 Model selection by cross-validation\n",
    "Remember, using the test data to select our best model is likely to result in _overfitting_. \n",
    "\n",
    "We will therefore start by splitting the training data into 5 folds of cross-validation. Scikit-learn also does that for us.\n",
    "\n",
    "scikit-learn model selection: http://scikit-learn.org/stable/model_selection.html#model-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Créate a KFold object\n",
    "kf = model_selection.KFold(n_splits=5,  # 5 folds\n",
    "                           shuffle=True # shuffle the samples before splitting \n",
    "                          )\n",
    "\n",
    "# Use kf to split Xtrain into 5 folds. \n",
    "# kf.split returns an iterator ((that would be consumed after one iteration). \n",
    "# We transform it in a list (on which we can iterate as often as we want).\n",
    "kf_indices = list(kf.split(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, (tr, te) in enumerate(kf_indices):\n",
    "    print(\"Training data for fold %d:\" % i, tr)\n",
    "    print(\"Test data for fold %d:\" % i, te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Linear models\n",
    "\n",
    "We will use scikit-learn to train a few [linear models](http://scikit-learn.org/stable/modules/linear_model.html#linear-model) on `(Xtrain, ytrain)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.1 Logistic regression\n",
    "How does a logistic regression perform on this data? We'll evaluate it by cross-validation, using the cross-validation folds we have generated above.\n",
    "\n",
    "But wait! What will our criterion be? There are several you can choose from on http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter. In this lab, we will use the [F1 score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question :__ What other criterion or criteria could you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Annswer:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a logistic regression model. We will use [scikit-learn's implementation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression), which includes a regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question:__ What is the relationship between the regularization parameter `C` and the regularization parameter `alpha` of the [ridge regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(C=1e10) # use a large penalty \n",
    "                                                # so as not to regularize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn allows us to directly compute the cross-validated F1 score (on the train test) of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = model_selection.cross_val_score(model, \n",
    "                                     Xtrain, y=ytrain, \n",
    "                                     scoring='f1', \n",
    "                                     cv=kf_indices)\n",
    "\n",
    "print([\"%.3f\" % value for value in f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ What is the average f1 score of the linear regression over all folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What are the weights that a logistic regression assigns to each variable on the train set? To determine this, we will train a logistic regression on the entire training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train a logistic regression on the entire train set\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize(12, 6))\n",
    "\n",
    "# Plot, for each feature, its coefficient in the model\n",
    "num_features = Xtrain.shape[1]\n",
    "plt.scatter(range(num_features), model.coef_)\n",
    "\n",
    "plt.xlabel('Feature', fontsize=14)\n",
    "tmp = plt.xticks(range(num_features), list(df.columns[1:]), \n",
    "                 rotation=90, fontsize=14)\n",
    "tmp = plt.ylabel('Weight', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Logistic regression weights', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Which feature do you think is the most important to predict edibility? Which one is the least important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.2 Ridge logistic regression\n",
    "\n",
    "Can we improve performance using regularization? By default, the logistic regression implemented in scikit-learn uses a l2 (i.e. ridge) penalty. Let us now try to find the optimal value of the regularization parameter `C`.\n",
    "\n",
    "Let us create 50 values of `C` for testing, equally spaced (in log scale) between $10^{-1}$ and $10^4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cvalues = np.logspace(-1, 4, 50)\n",
    "\n",
    "f1_per_c = [] # will store the f1 values for all 50 values of C\n",
    "weights_per_c = [] #  will store the weights associated with each feature \n",
    "                       # for all 50 values of C\n",
    "for cval in cvalues:\n",
    "    # Create a logistic regression ridge model\n",
    "    model = linear_model.LogisticRegression(C=cval)\n",
    "    \n",
    "    # Compute the model's cross-validated performance\n",
    "    f1 = model_selection.cross_val_score(model, \n",
    "                                           Xtrain, y=ytrain, \n",
    "                                           scoring='f1', \n",
    "                                           cv=kf_indices)\n",
    "    f1_per_c.append(f1)\n",
    "    \n",
    "    # Train the model on the entire data set and store the regression coefficients\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    weights_per_c.append(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape weights_per_c into a (number of values of C, number of features) array\n",
    "weights_per_c = np.array(weights_per_c)\n",
    "weights_per_c.shape = (50, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot, for each feature, the regression weight as a function of alpha\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "lines = plt.plot(cvalues, weights_per_c)\n",
    "plt.xscale('log')\n",
    "tmp = plt.legend(lines, list(df.columns[1:]), frameon=False, \n",
    "                 loc=(1, 0), fontsize=14)\n",
    "\n",
    "tmp = plt.xlabel('C', fontsize=14)\n",
    "tmp = plt.ylabel('Weight', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Logistic ridge regression weights', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Is this consistent with what we observed for the non-regularized logistic regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Plot the f1 score (averaged across the 5 folds) as a function of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ What is the optimal value of C and what is the corresponding average cross-validated f1? Use `np.argmin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ How does the regularized logistic ridge regression compare to the vanilla logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Non-linear models\n",
    "Can a non-linear model improve the performance on this data? Our performance are already very good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 5. Final model\n",
    "\n",
    "__Question:__ Based on the above analyses, which model do you finally choose as the most performant? What is its confusion matrix on the test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Answer:__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
